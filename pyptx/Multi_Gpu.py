import ctypes

class PyPTXMultiGPU:
    def __init__(self, num_gpus):
        self.num_gpus = num_gpus
        self.contexts = []

        # Create contexts for each GPU
        for i in range(num_gpus):
            device = ctypes.c_int(i)
            context = ctypes.c_void_p()
            nvcuda.cuCtxCreate(ctypes.byref(context), 0, device)
            self.contexts.append(context)
            print(f"ðŸ”¥ Created GPU Context for Device {i}")

    def execute(self):
        """Executes workload across multiple GPUs"""
        self.distribute_workload()

    def distribute_workload(self):
        """Function to assign workload to GPUs"""
        for i in range(self.num_gpus):
            context = self.contexts[i]
            nvcuda.cuCtxSetCurrent(context)  # Switch to the GPU context

            # Launch a tensor operation
            print(f"ðŸš€ Executing on GPU {i}")
            # Add your tensor kernel execution here

# Load NVIDIA driver
nvcuda = ctypes.WinDLL("nvcuda.dll")

# Initialize CUDA manually
nvcuda.cuInit(0)

# Detect all available GPUs
num_gpus = ctypes.c_int()
nvcuda.cuDeviceGetCount(ctypes.byref(num_gpus))
print(f"ðŸš€ Found {num_gpus.value} GPUs!")

# Create an instance of PyPTXMultiGPU
multi_gpu = PyPTXMultiGPU(num_gpus.value)
multi_gpu.execute()
